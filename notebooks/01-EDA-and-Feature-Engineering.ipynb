{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Feature Engineering\n",
    "\n",
    "This notebook explores the `processed_data.csv` file, visualizes key relationships, and engineers new features for our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "# Note: You must run `run_pipeline.py --skip-db` first to generate this file.\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed_data.csv', parse_dates=['Date'])\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: `data/processed_data.csv` not found.\")\n",
    "    print(\"Please run `run_pipeline.py --skip-db` from the root directory first.\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"--- Descriptive Statistics ---\")\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"--- Correlation Matrix ---\")\n",
    "    numeric_cols = df.select_dtypes(include=np.number)\n",
    "    correlation_matrix = numeric_cols.corr()\n",
    "    display(correlation_matrix[['Close']].sort_values(by='Close', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"--- Creating New Features ---\")\n",
    "    # Sort by Ticker and Date to ensure correct order for time-series features\n",
    "    df.sort_values(by=['Ticker', 'Date'], inplace=True)\n",
    "    \n",
    "    # Lagged Price Features\n",
    "    df['price_change_1d'] = df.groupby('Ticker')['Close'].pct_change(1)\n",
    "    df['price_change_5d'] = df.groupby('Ticker')['Close'].pct_change(5)\n",
    "    \n",
    "    # Lagged Sentiment Features\n",
    "    df['vader_1d_lag'] = df.groupby('Ticker')['vader_avg_score'].shift(1)\n",
    "    df['finbert_1d_lag'] = df.groupby('Ticker')['finbert_avg_score'].shift(1)\n",
    "    \n",
    "    # Moving Averages\n",
    "    df['sma_7d'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=7).mean())\n",
    "    df['sma_30d'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(window=30).mean())\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    def calculate_rsi(series, window=14):\n",
    "        delta = series.diff(1)\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "    df['rsi_14d'] = df.groupby('Ticker')['Close'].transform(lambda x: calculate_rsi(x))\n",
    "    \n",
    "    print(\"New features created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"--- Creating Target Variable ---\")\n",
    "    # The target is to predict if the next day's price will go up (1) or down (0).\n",
    "    df['next_day_close'] = df.groupby('Ticker')['Close'].shift(-1)\n",
    "    df['target'] = (df['next_day_close'] > df['Close']).astype(int)\n",
    "    \n",
    "    print(\"Target variable 'target' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"--- Preparing Final ML Dataset ---\")\n",
    "    # Drop rows with NaN values created by lags and rolling windows\n",
    "    ml_df = df.dropna()\n",
    "    \n",
    "    # Select feature columns and the target\n",
    "    feature_cols = [\n",
    "        'price_change_1d', 'price_change_5d', \n",
    "        'vader_1d_lag', 'finbert_1d_lag',\n",
    "        'sma_7d', 'sma_30d', 'rsi_14d',\n",
    "        'article_count'\n",
    "    ]\n",
    "    final_df = ml_df[feature_cols + ['target', 'Date', 'Ticker']]\n",
    "    \n",
    "    # Save the final dataset\n",
    "    output_path = '../data/ml_ready_data.csv'\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Final ML-ready dataset created with {len(final_df)} rows.\")\n",
    "    print(f\"Saved to {output_path}\")\n",
    "    display(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
